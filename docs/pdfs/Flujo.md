# Flujo Detallado del Agente NetMind

Este documento describe en detalle el flujo completo de ejecuci√≥n del agente, desde que el usuario env√≠a una consulta hasta que recibe la respuesta final.

## üîÑ Diagrama del Flujo

```
Usuario ‚Üí POST /agent/query (o /agent/query/stream para SSE)
   ‚îÇ
   ‚îú‚îÄ> backend/src/api/agent.py:agent_query() (o streaming.py:agent_query_stream())
   ‚îÇ    ‚îÇ
   ‚îú‚îÄ> SessionManager.get_session()
   ‚îÇ    ‚îî‚îÄ> backend/src/core/state_manager.py
   ‚îÇ         ‚îî‚îÄ> Retorna: AgentState (backend/src/models/schemas.py)
   ‚îÇ    ‚îÇ
   ‚îú‚îÄ> Convierte AgentState ‚Üí GraphState
   ‚îÇ    ‚îî‚îÄ> backend/src/core/graph_state.py:GraphState
   ‚îÇ    ‚îÇ
   ‚îú‚îÄ> graph.invoke(initial_state) o graph.astream_events() (para streaming)
   ‚îÇ    ‚îî‚îÄ> backend/src/agent/agent_graph.py
   ‚îÇ         ‚îÇ
   ‚îÇ         ‚îú‚îÄ> Planner Node
   ‚îÇ         ‚îÇ    ‚îî‚îÄ> NetMindAgent.decide()
   ‚îÇ         ‚îÇ         ‚îî‚îÄ> backend/src/agent/router.py
   ‚îÇ         ‚îÇ              ‚îî‚îÄ> Usa: LLMClient (backend/src/agent/llm_client.py)
   ‚îÇ         ‚îÇ                   ‚îî‚îÄ> Retorna: {tool, plan_steps, reason}
   ‚îÇ         ‚îÇ
   ‚îÇ         ‚îú‚îÄ> Orchestrator Node
   ‚îÇ         ‚îÇ    ‚îî‚îÄ> Decide siguiente componente
   ‚îÇ         ‚îÇ
   ‚îÇ         ‚îú‚îÄ> Executor Node (si hay plan_steps)
   ‚îÇ         ‚îÇ    ‚îú‚îÄ> determine_tool_from_step()
   ‚îÇ         ‚îÇ    ‚îÇ    ‚îî‚îÄ> backend/src/agent/tool_executors.py
   ‚îÇ         ‚îÇ    ‚îÇ
   ‚îÇ         ‚îÇ    ‚îî‚îÄ> execute_*_tool()
   ‚îÇ         ‚îÇ         ‚îú‚îÄ> RAG: backend/src/tools/rag_tool.py
   ‚îÇ         ‚îÇ         ‚îÇ    ‚îî‚îÄ> Usa: embeddings_service, qdrant_repository
   ‚îÇ         ‚îÇ         ‚îÇ
   ‚îÇ         ‚îÇ         ‚îú‚îÄ> IP: backend/src/tools/ip_tool.py
   ‚îÇ         ‚îÇ         ‚îÇ    ‚îî‚îÄ> Ejecuta comandos de red
   ‚îÇ         ‚îÇ         ‚îÇ
   ‚îÇ         ‚îÇ         ‚îî‚îÄ> DNS: backend/src/tools/dns_tool.py
   ‚îÇ         ‚îÇ              ‚îî‚îÄ> Consultas DNS
   ‚îÇ         ‚îÇ
   ‚îÇ         ‚îú‚îÄ> Synthesizer Node
   ‚îÇ         ‚îÇ    ‚îî‚îÄ> Combina resultados
   ‚îÇ         ‚îÇ         ‚îî‚îÄ> Usa: LLMClient.generate()
   ‚îÇ         ‚îÇ
   ‚îÇ         ‚îî‚îÄ> Supervisor Node
   ‚îÇ              ‚îú‚îÄ> Valida y mejora respuesta
   ‚îÇ              ‚îÇ    ‚îî‚îÄ> Usa: LLMClient.generate()
   ‚îÇ              ‚îî‚îÄ> Captura para RAGAS: backend/src/utils/ragas_evaluator.py
   ‚îÇ
   ‚îî‚îÄ> Retorna supervised_output (o stream en tiempo real para SSE)
        ‚îî‚îÄ> backend/src/api/agent.py (o streaming.py)
             ‚îú‚îÄ> SessionManager.update_session()
             ‚îî‚îÄ> Retorna respuesta al usuario (o stream de tokens)
```

---

## üìù Flujo Paso a Paso

### 1. Usuario ‚Üí POST /agent/query (o /agent/query/stream)

**Acci√≥n**: El usuario env√≠a una petici√≥n HTTP POST al endpoint `/agent/query` o `/agent/query/stream` (para streaming)

**Endpoints disponibles**:
- `/agent/query`: Respuesta completa al finalizar
- `/agent/query/stream`: Streaming de respuesta en tiempo real (SSE)

**Datos enviados**:
```json
{
  "session_id": "session-123",
  "user_id": "user-456",
  "messages": [
    {
      "role": "user",
      "content": "¬øQu√© es un ping?"
    }
  ]
}
```

---

### 2. backend/src/api/agent.py:agent_query() (o streaming.py:agent_query_stream())

**Ubicaci√≥n**: 
- `backend/src/api/agent.py` - Para consultas est√°ndar
- `backend/src/api/streaming.py` - Para consultas con streaming (SSE)

**Acciones realizadas**:

1. **Validaciones**:
   - Verifica que `query.messages` no est√© vac√≠o
   - Verifica que haya al menos un mensaje con `role="user"`
   - Verifica que el √∫ltimo mensaje del usuario no est√© vac√≠o

2. **Obtiene o crea sesi√≥n**:
   - Llama a `session_manager.get_session(query.session_id, query.user_id)`
   - Si la sesi√≥n no existe, crea un nuevo `AgentState`

3. **Agrega mensaje del usuario**:
   - Compara con el √∫ltimo mensaje en el contexto de la sesi√≥n
   - Si es un mensaje nuevo, lo agrega con `session_state.add_message("user", user_message)`

4. **Convierte mensajes**:
   - Filtra solo mensajes `user` y `assistant` (ignora `system`)
   - Convierte a formato LangChain:
     - `role="user"` ‚Üí `HumanMessage(content=msg.content)`
     - `role="assistant"` ‚Üí `AIMessage(content=msg.content)`

5. **Crea estado inicial del grafo**:
   - Crea `GraphState(messages=graph_messages)`

**C√≥digo relevante**:
```python
# Convertir mensajes de AgentState a mensajes de LangChain
graph_messages = []
for msg in session_state.context_window:
    if msg.role == "user":
        graph_messages.append(HumanMessage(content=msg.content))
    elif msg.role == "assistant":
        graph_messages.append(AIMessage(content=msg.content))

# Crear estado inicial del grafo
initial_state = GraphState(messages=graph_messages)
```

---

### 3. SessionManager.get_session()

**Ubicaci√≥n**: `backend/src/core/state_manager.py` (o `backend/src/core/redis_session_manager.py` si se usa Redis)

**Acciones realizadas**:

1. **Busca sesi√≥n existente**:
   - Busca en `self._sessions` usando `session_id` como clave

2. **Crea nueva sesi√≥n si no existe**:
   ```python
   AgentState(
       session_id=session_id,
       user_id=user_id,
       context_window=[],
       variables={},
       results={}
   )
   ```

3. **Crea lock para thread-safety**:
   - Crea un `threading.Lock` para la sesi√≥n

4. **Retorna AgentState**:
   - Retorna la sesi√≥n existente o la nueva creada

---

### 4. Convierte AgentState ‚Üí GraphState

**Ubicaci√≥n**: 
- `backend/src/api/agent.py` (para consultas est√°ndar)
- `backend/src/api/streaming.py` (para streaming)
- `backend/src/core/graph_state.py` (definici√≥n de GraphState)

**Acciones realizadas**:

1. **Extrae mensajes**:
   - Toma mensajes de `session_state.context_window`

2. **Convierte formato**:
   - Convierte cada `Message` (Pydantic) a `HumanMessage`/`AIMessage` (LangChain)

3. **Crea GraphState**:
   - `GraphState` incluye:
     - `messages`: Lista de mensajes (acumulativo)
     - `plan_steps`: Lista de pasos del plan
     - `results`: Resultados de herramientas
     - `final_output`: Respuesta final
     - `supervised_output`: Respuesta validada
     - `thought_chain`: Cadena de pensamiento

**Estructura GraphState**:
```python
class GraphState(BaseModel):
    messages: Annotated[List[AnyMessage], add_messages] = []
    plan_steps: Annotated[List[str], LastValue(list)] = []
    results: Annotated[List[Any], LastValue(list)] = []
    final_output: Annotated[Optional[str], LastValue(str)] = None
    supervised_output: Annotated[Optional[str], LastValue(str)] = None
    quality_score: Annotated[Optional[float], LastValue(float)] = None
    # ... m√°s campos
```

---

### 5. graph.invoke(initial_state) o graph.astream_events()

**Ubicaci√≥n**: `backend/src/agent/agent_graph.py`

**Acci√≥n**: 
- **Consulta est√°ndar**: Ejecuta el grafo con `graph.invoke()` o `graph.ainvoke()`
- **Streaming**: Ejecuta el grafo con `graph.astream_events()` para capturar tokens en tiempo real

**Flujo del grafo**:
```
START ‚Üí Planner ‚Üí Orchestrator ‚Üí [Executor/Synthesizer] ‚Üí Supervisor ‚Üí END
```

El grafo se ejecuta secuencialmente, pasando el estado entre nodos. En modo streaming, los tokens del LLM se capturan mientras se generan.

---

### 6. Planner Node

**Funci√≥n**: `planner_node(state: GraphState)`

**Ubicaci√≥n**: `backend/src/agent/agent_graph.py` (l√≠neas 170-233)

**Acciones realizadas**:

1. **Extrae prompt del usuario**:
   - Busca el √∫ltimo `HumanMessage` en `state.messages`
   - Funci√≥n: `get_user_prompt_from_messages(state.messages)`

2. **Convierte mensajes a AgentState**:
   - Usa `messages_to_agent_state()` para obtener contexto
   - Toma los √∫ltimos 10 mensajes para contexto

3. **Llama a NetMindAgent.decide()**:
   - Crea instancia de `NetMindAgent`
   - Llama a `router.decide(user_prompt, context)`

4. **Procesa decisi√≥n**:
   - Si hay `rejection_message` ‚Üí retorna plan vac√≠o y mensaje de rechazo
   - Si no hay rechazo ‚Üí extrae `plan_steps` de la decisi√≥n

5. **Registra pensamiento**:
   - Agrega entrada a `thought_chain` con el plan generado

6. **Retorna**:
   ```python
   {
       "plan_steps": plan_steps,
       "thought_chain": thought_chain
   }
   ```

---

### 7. NetMindAgent.decide()

**Ubicaci√≥n**: `backend/src/agent/router.py` (l√≠neas 26-245)

**Acciones realizadas**:

1. **Validaci√≥n de relevancia tem√°tica**:
   - Crea prompt para verificar si la pregunta es sobre redes/telecomunicaciones
   - Llama a LLM con `temperature=0.0`, `max_tokens=10`
   - Espera respuesta: "relevante" o "no_relevante"
   - Si no es relevante ‚Üí retorna:
     ```python
     {
         "tool": "none",
         "reason": "out_of_topic",
         "plan_steps": [],
         "rejection_message": "Lo siento, solo puedo responder..."
     }
     ```

2. **Si es relevante, genera plan**:
   - Crea prompt detallado con:
     - Pregunta del usuario
     - Contexto (√∫ltimos 5 mensajes)
     - Reglas para seleccionar herramienta (RAG/IP/DNS)
     - Instrucciones para generar `plan_steps` espec√≠ficos
   - Llama a LLM para obtener JSON con:
     - `tool`: "rag", "ip", "dns" o "none"
     - `reason`: explicaci√≥n breve
     - `plan_steps`: lista de pasos ejecutables

3. **Procesa respuesta del LLM**:
   - Limpia delimitadores Markdown (```json)
   - Extrae JSON con regex
   - Parsea JSON
   - Valida y normaliza `plan_steps`:
     - Si est√° vac√≠o, genera uno por defecto seg√∫n la herramienta
     - Filtra pasos vagos ("ensure", "elaborate", etc.)

4. **Retorna**:
   ```python
   {
       "tool": "rag|ip|dns|none",
       "reason": "...",
       "plan_steps": ["step1", "step2", ...]
   }
   ```

**Ejemplo de plan_steps**:
- `["retrieve information about what ping is"]` ‚Üí RAG
- `["ping to google.com"]` ‚Üí IP
- `["query all DNS records for google.com"]` ‚Üí DNS

---

### 8. Orchestrator Node

**Funci√≥n**: `orchestrator_node(state: GraphState)`

**Ubicaci√≥n**: `backend/src/agent/agent_graph.py` (l√≠neas 236-328)

**Acciones realizadas**:

1. **Lee el estado**:
   - `plan_steps`: pasos pendientes
   - `results`: resultados acumulados
   - `rejection_message`: mensaje de rechazo (si existe)

2. **Toma decisi√≥n**:
   - Si hay `rejection_message` ‚Üí `next_component = "Sintetizador"`
   - Si no hay `plan_steps` ‚Üí `next_component = "Sintetizador"`
   - Si hay `results` y no hay `plan_steps` ‚Üí `next_component = "Sintetizador"`
   - Si hay `plan_steps` ‚Üí `next_component = "Agente_Ejecutor"`
   - Fallback ‚Üí `next_component = "Sintetizador"`

3. **Registra pensamiento**:
   - Agrega entrada a `thought_chain` con la decisi√≥n

4. **Retorna**:
   ```python
   {
       "next_component": "Agente_Ejecutor" | "Sintetizador",
       "thought_chain": thought_chain
   }
   ```

---

### 9. Executor Node (si hay plan_steps)

**Funci√≥n**: `ejecutor_agent_node(state: GraphState)`

**Ubicaci√≥n**: `backend/src/agent/agent_graph.py` (l√≠neas 331-425)

**Acciones realizadas**:

1. **Extrae siguiente paso**:
   - Toma el primer elemento de `plan_steps`
   - Crea copia: `plan_steps_copy = list(plan_steps)`
   - Elimina el primer paso: `current_step = plan_steps_copy.pop(0)`

2. **Obtiene prompt del usuario**:
   - Extrae el √∫ltimo mensaje del usuario de `state.messages`
   - Limita a 6000 caracteres si es muy largo

3. **Determina herramienta**:
   - Llama a `determine_tool_from_step(current_step, user_prompt)`

4. **Ejecuta herramienta**:
   - `tool_name == "rag"` ‚Üí `execute_rag_tool(current_step, user_prompt, state.messages)`
   - `tool_name == "ip"` ‚Üí `execute_ip_tool(current_step, user_prompt, state.messages)`
   - `tool_name == "dns"` ‚Üí `execute_dns_tool(current_step, user_prompt, state.messages)`

5. **Guarda resultado**:
   - Agrega el resultado a `state.results`
   - Actualiza `executed_tools` y `executed_steps`

6. **Registra pensamiento**:
   - Agrega entrada con el estado de ejecuci√≥n

7. **Retorna**:
   ```python
   {
       "plan_steps": plan_steps_copy,  # Sin el paso ejecutado
       "results": accumulated,
       "executed_tools": executed_tools_list,
       "executed_steps": executed_steps_list,
       "thought_chain": thought_chain
   }
   ```

8. **Decisi√≥n de ruteo**:
   - Si quedan pasos en `plan_steps` ‚Üí vuelve a Orchestrator
   - Si no quedan pasos ‚Üí va a Synthesizer

---

### 10. determine_tool_from_step()

**Ubicaci√≥n**: `backend/src/agent/tool_executors.py` (l√≠neas 856-904)

**Acciones realizadas**:

1. **Crea prompt para LLM**:
   - Incluye el paso del plan y el prompt original
   - Describe las herramientas disponibles (RAG/IP/DNS)
   - Pide respuesta: "rag", "ip" o "dns"

2. **Llama a LLM**:
   - Usa `llm.generate(tool_determination_prompt)`

3. **Procesa respuesta**:
   - Normaliza a min√∫sculas
   - Busca "dns", "rag" o "ip" en la respuesta

4. **Fallback heur√≠stico** (si falla LLM):
   - Busca palabras clave en el paso:
     - DNS: "dns", "domain", "mx", "nameserver", "registro dns"
     - IP: "ping", "trace", "traceroute", "compare", "ip", "network"
     - RAG: por defecto

5. **Retorna**: `"rag"`, `"ip"` o `"dns"`

---

### 11. execute_*_tool()

**Ubicaci√≥n**: `backend/src/agent/tool_executors.py`
- `execute_rag_tool()`: l√≠neas 429-640
- `execute_ip_tool()`: l√≠neas 59-114
- `execute_dns_tool()`: l√≠neas 643-853

#### execute_rag_tool():

1. **Extrae contexto de conversaci√≥n**:
   - Toma los √∫ltimos 10 mensajes anteriores al actual
   - Formatea como string

2. **Llama a rag_tool.query()**:
   - Pasa `user_prompt` y `conversation_context`
   - El RAG tool busca en documentos usando embeddings

3. **Retorna**: `{answer, contexts, hits, source}`

#### execute_ip_tool():

1. **Detecta tipo de operaci√≥n**:
   - Analiza el paso y el prompt
   - Detecta: "ping", "traceroute", "compare"

2. **Extrae hosts/IPs**:
   - Busca IPs o dominios v√°lidos en el texto

3. **Ejecuta operaci√≥n**:
   - `ping` ‚Üí `ip_tool.ping(host)`
   - `traceroute` ‚Üí `ip_tool.tracert(host)`
   - `compare` ‚Üí `ip_tool.compare(ip1, ip2)`

4. **Retorna**: `{type, results, ...}`

#### execute_dns_tool():

1. **Detecta tipo de consulta**:
   - Analiza el paso y el prompt
   - Detecta: "all records", "MX", "TXT", "NS", "comparison", "SPF", "DMARC", etc.

2. **Extrae dominio**:
   - Busca dominio v√°lido en el texto con regex

3. **Ejecuta consulta**:
   - `get_all_records(domain)` ‚Üí todos los registros
   - `query(domain, record_type)` ‚Üí registro espec√≠fico
   - `compare_dns(domain1, domain2)` ‚Üí comparaci√≥n
   - `check_spf/dmarc(domain)` ‚Üí verificaci√≥n

4. **Retorna**: `{domain, records, summary_text, ...}`

---

### 12. Synthesizer Node

**Funci√≥n**: `synthesizer_node(state: GraphState)`

**Ubicaci√≥n**: `backend/src/agent/agent_graph.py` (l√≠neas 858-1185)

**Acciones realizadas**:

1. **Verifica mensaje de rechazo**:
   - Si hay `rejection_message` ‚Üí retorna ese mensaje directamente

2. **Analiza resultados**:
   - Detecta qu√© herramientas se usaron:
     - RAG: tiene `'answer'` en el resultado
     - IP: tiene `'comparison'`, `'traceroute'`, `'ip'`, etc.
     - DNS: tiene `'domain'`, `'records'`, etc.

3. **Casos de s√≠ntesis**:

   **Solo RAG**:
   - Extrae `answer` de cada resultado RAG
   - Analiza complejidad de la pregunta (simple/moderada/compleja)
   - Genera respuesta con LLM:
     - Prompt: combina pregunta + respuestas RAG
     - Instrucciones: fidelidad, longitud adaptativa, lenguaje natural
     - Ajusta longitud seg√∫n complejidad
   - Retorna respuesta procesada

   **Solo IP o Solo DNS**:
   - Formatea resultados usando `ip_tool.format_result()` o `dns_tool.format_result()`
   - Retorna resultados formateados directamente (sin LLM)

   **RAG + IP/DNS**:
   - Combina respuestas RAG con resultados t√©cnicos
   - Genera respuesta con LLM que integra:
     - Informaci√≥n conceptual (RAG)
     - Resultados t√©cnicos (IP/DNS)
   - Retorna respuesta combinada

4. **Retorna**: `{"final_output": respuesta_final}`

---

### 13. Supervisor Node

**Funci√≥n**: `supervisor_node(state: GraphState)`

**Ubicaci√≥n**: `backend/src/agent/agent_graph.py` (l√≠neas 428-855)

**Acciones realizadas**:

1. **Lee final_output del estado**

2. **Detecta si est√° fuera de tema**:
   - Usa LLM para verificar si la respuesta indica que la pregunta est√° fuera de tema
   - Si es as√≠, pasa la respuesta sin modificar

3. **Eval√∫a calidad**:
   - Crea prompt para evaluar calidad (0-10)
   - Llama a LLM para obtener puntuaci√≥n
   - Normaliza a rango 0-1

4. **Analiza complejidad**:
   - Usa LLM para determinar: "simple", "moderada" o "compleja"
   - Define longitud m√°xima seg√∫n complejidad:
     - Simple: 200 caracteres
     - Moderada: 600-1500 caracteres
     - Compleja: 2000 caracteres

5. **Mejora respuesta si es necesario**:
   - Si calidad < 0.5 o muy larga:
     - Crea prompt de mejora con instrucciones espec√≠ficas
     - Llama a LLM para mejorar
     - Ajusta longitud si es necesario

6. **Captura para RAGAS** (evaluaci√≥n):
   - Extrae contextos de `state.results`
   - Captura: pregunta, respuesta, contextos
   - Ejecuta evaluaci√≥n en background (thread separado)

7. **Retorna**:
   ```python
   {
       "supervised_output": respuesta_mejorada,
       "quality_score": puntuaci√≥n
   }
   ```

---

### 14. Retorna supervised_output

**Ubicaci√≥n**: 
- `backend/src/api/agent.py` (despu√©s de `graph.invoke()` o `graph.ainvoke()`)
- `backend/src/api/streaming.py` (streaming en tiempo real con `graph.astream_events()`)

**Acciones realizadas**:

1. **Extrae respuesta final**:
   - Lee `supervised_output` del estado final
   - Si no existe, usa `final_output`
   - Si no existe, usa mensaje por defecto

2. **Construye respuesta**:
   - Crea `new_messages` con la respuesta del asistente
   - Extrae `executed_tools` y `executed_steps` del estado
   - Construye objeto `decision` con informaci√≥n de ejecuci√≥n

3. **Actualiza sesi√≥n**:
   - Agrega respuesta del asistente al contexto: `session_state.add_message("assistant", assistant_response)`
   - Persiste sesi√≥n: `session_manager.update_session(query.session_id, session_state)`

4. **Retorna respuesta HTTP**:
   ```json
   {
       "session_id": "...",
       "new_messages": [
           {
               "role": "assistant",
               "content": "..."
           }
       ],
       "decision": {
           "tool": "rag|ip|dns",
           "plan_steps": [...],
           "executed_tools": [...]
       },
       "session_context_length": 5
   }
   ```

---

## üìÅ Estructura de Archivos

```
backend/
‚îú‚îÄ‚îÄ main.py                    # Punto de entrada FastAPI
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/                   # Capa de API REST
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent.py          # Endpoint principal /agent/query
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ files.py           # Endpoint para gesti√≥n de archivos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ streaming.py      # Endpoint para streaming de respuestas (SSE)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ agent/                 # L√≥gica del agente (grafo LangGraph)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent_graph.py    # Grafo principal con 5 nodos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router.py         # NetMindAgent (decisi√≥n de herramientas)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tool_executors.py # Ejecutores de herramientas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_client.py     # Cliente OpenAI
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ helpers.py        # Funciones auxiliares
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ tools/                 # Herramientas especializadas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag_tool.py       # RAG (b√∫squeda en documentos)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ip_tool.py        # Operaciones de red (ping, traceroute)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dns_tool.py       # Consultas DNS
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/                  # Componentes centrales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph_state.py    # GraphState (estado compartido)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state_manager.py  # SessionManager (gesti√≥n de sesiones)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache.py          # Sistema de cach√©
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ redis_session_manager.py # Gesti√≥n de sesiones Redis
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                # Modelos de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py        # Pydantic schemas (AgentState, Message)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database.py       # Modelos de base de datos
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ repositories/         # Acceso a datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qdrant_repository.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_repository.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ session_repository.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ services/              # Servicios de negocio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ embeddings_service.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/                 # Utilidades
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ragas_callback.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ragas_evaluator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ text_processing.py # Procesamiento de texto
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ settings.py           # Configuraci√≥n centralizada
```

---

## üîß Componentes Principales

### 1. API Layer (`src/api/`)
- **agent.py**: Endpoint `/agent/query` que recibe consultas y ejecuta el grafo
- **files.py**: Endpoints para gesti√≥n de archivos PDF
- **streaming.py**: Endpoint `/agent/query/stream` para streaming de respuestas (SSE)

### 2. Agent Layer (`src/agent/`)
- **agent_graph.py**: Grafo LangGraph con 5 nodos (Planner, Orchestrator, Executor, Synthesizer, Supervisor)
- **router.py**: NetMindAgent que decide qu√© herramienta usar
- **tool_executors.py**: Ejecutores que llaman a las herramientas espec√≠ficas
- **llm_client.py**: Cliente para interactuar con OpenAI

### 3. Tools (`src/tools/`)
- **rag_tool.py**: B√∫squeda sem√°ntica en documentos indexados
- **ip_tool.py**: Operaciones de red (ping, traceroute, comparaci√≥n)
- **dns_tool.py**: Consultas DNS y verificaciones

### 4. Core (`src/core/`)
- **graph_state.py**: Estado compartido del grafo (GraphState)
- **state_manager.py**: Gesti√≥n de sesiones (SessionManager)
- **cache.py**: Sistema de cach√© con Redis

### 5. Models (`src/models/`)
- **schemas.py**: Schemas Pydantic (AgentState, Message, AgentQuery)
- **database.py**: Modelos SQLAlchemy

---

## üîÑ Resumen del Flujo Completo

```
Usuario env√≠a pregunta
    ‚Üì
API valida y obtiene sesi√≥n
    ‚Üì
Convierte a GraphState
    ‚Üì
Planner: Analiza pregunta ‚Üí Genera plan (NetMindAgent)
    ‚Üì
Orchestrator: Decide siguiente paso
    ‚Üì
Executor: Ejecuta herramienta (RAG/IP/DNS)
    ‚Üì (si hay m√°s pasos, vuelve a Orchestrator)
Synthesizer: Combina resultados ‚Üí Genera respuesta
    ‚Üì
Supervisor: Valida y mejora respuesta
    ‚Üì
API: Guarda en sesi√≥n ‚Üí Retorna al usuario
```

Cada paso actualiza el estado compartido (`GraphState`) que se propaga autom√°ticamente entre nodos gracias a LangGraph.

---

## üìä Flujo de Datos

```
Usuario ‚Üí API ‚Üí GraphState (messages)
                ‚Üì
            Planner ‚Üí plan_steps
                ‚Üì
            Orchestrator ‚Üí next_component
                ‚Üì
            Executor ‚Üí results
                ‚Üì
            Synthesizer ‚Üí final_output
                ‚Üì
            Supervisor ‚Üí supervised_output
                ‚Üì
            API ‚Üí Usuario
```

---

## üîç Dependencias entre M√≥dulos

```
api/agent.py
  ‚îú‚îÄ> core/state_manager.py (SessionManager)
  ‚îú‚îÄ> core/graph_state.py (GraphState)
  ‚îú‚îÄ> agent/agent_graph.py (graph)
  ‚îî‚îÄ> models/schemas.py (AgentState, Message)

agent/agent_graph.py
  ‚îú‚îÄ> agent/router.py (NetMindAgent)
  ‚îú‚îÄ> agent/tool_executors.py (execute_*_tool)
  ‚îú‚îÄ> agent/llm_client.py (LLMClient)
  ‚îú‚îÄ> core/graph_state.py (GraphState)
  ‚îî‚îÄ> models/schemas.py (AgentState)

agent/tool_executors.py
  ‚îú‚îÄ> tools/rag_tool.py (RAGTool)
  ‚îú‚îÄ> tools/ip_tool.py (IPTool)
  ‚îú‚îÄ> tools/dns_tool.py (DNSTool)
  ‚îî‚îÄ> agent/llm_client.py (LLMClient)

tools/rag_tool.py
  ‚îú‚îÄ> services/embeddings_service.py
  ‚îú‚îÄ> repositories/qdrant_repository.py
  ‚îî‚îÄ> repositories/document_repository.py
```

---

## üìù Notas Importantes

1. **Estado Compartido**: El `GraphState` se propaga autom√°ticamente entre nodos usando LangGraph
2. **Thread-Safety**: El `SessionManager` usa locks para garantizar thread-safety
3. **Cach√©**: Las respuestas RAG se cachean por 1 hora (configurable)
4. **Contexto de Conversaci√≥n**: Se mantiene por `session_id` y se limita a 20 mensajes
5. **Validaci√≥n Tem√°tica**: Se valida que las preguntas sean sobre redes/telecomunicaciones
6. **Evaluaci√≥n RAGAS**: Se ejecuta en background para no bloquear la respuesta

